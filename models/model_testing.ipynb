{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a809ecd",
   "metadata": {},
   "source": [
    "Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "293b8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from scipy.stats import randint, uniform\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f735e19",
   "metadata": {},
   "source": [
    "Load the dataset and perform initial preprocessing by dropping non-relevant columns and separating features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96514d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature value counts (first 5 features):\n",
      "   Bit_1  Bit_2  Bit_4  Bit_8  Bit_9\n",
      "0    106    170    170    170    170\n",
      "1     65      1      1      1      1\n",
      "Total dataset size: 171 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('aggregated_plants.csv')\n",
    "\n",
    "# Dropping non-relevant columns\n",
    "df = df.drop(columns=['Plant_Species', 'Reference', 'BitInterpretations'])\n",
    "\n",
    "# Handle missing values if necessary\n",
    "df = df.dropna()\n",
    "\n",
    "# Separating features and target\n",
    "features = df.drop('Salmonella Typhimurium', axis=1)\n",
    "target = df['Salmonella Typhimurium']\n",
    "\n",
    "# Verify that all features are binary\n",
    "print(\"Feature value counts (first 5 features):\")\n",
    "print(features.iloc[:, :5].apply(pd.value_counts))\n",
    "\n",
    "# Assign features and target to X and y\n",
    "X = features\n",
    "y = target\n",
    "\n",
    "print(f\"Total dataset size: {X.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "27cce16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation metrics for Logistic Regression on all features:\n",
      "  accuracy:\n",
      "    Training: 0.8597 (+/- 0.0132)\n",
      "    Testing: 0.7896 (+/- 0.0726)\n",
      "  roc_auc:\n",
      "    Training: 0.9412 (+/- 0.0072)\n",
      "    Testing: 0.8173 (+/- 0.0577)\n",
      "  sensitivity:\n",
      "    Training: 0.8305 (+/- 0.0210)\n",
      "    Testing: 0.7438 (+/- 0.1442)\n",
      "  specificity:\n",
      "    Training: 0.8899 (+/- 0.0069)\n",
      "    Testing: 0.8338 (+/- 0.1357)\n",
      "  precision:\n",
      "    Training: 0.8864 (+/- 0.0087)\n",
      "    Testing: 0.8458 (+/- 0.1135)\n",
      "  npv:\n",
      "    Training: 0.8355 (+/- 0.0177)\n",
      "    Testing: 0.7745 (+/- 0.0899)\n",
      "  mcc:\n",
      "    Training: 0.7211 (+/- 0.0256)\n",
      "    Testing: 0.5982 (+/- 0.1434)\n",
      "  f1:\n",
      "    Training: 0.8575 (+/- 0.0146)\n",
      "    Testing: 0.7766 (+/- 0.0843)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, matthews_corrcoef,\n",
    "    f1_score, make_scorer, confusion_matrix, roc_auc_score, classification_report\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define custom scorers\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "def npv_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fn = cm[1, 0]\n",
    "    return tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "# Create scorers dictionary\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'sensitivity': make_scorer(recall_score, zero_division=0),\n",
    "    'specificity': make_scorer(specificity_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'npv': make_scorer(npv_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'f1': make_scorer(f1_score, zero_division=0)\n",
    "}\n",
    "\n",
    "# Initialize the estimator with regularization parameter C\n",
    "estimator = LogisticRegression(penalty='l1', solver='saga', C=0.85, max_iter=5000, random_state=0)\n",
    "\n",
    "# Set up the stratified k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform cross-validation on the entire dataset\n",
    "cv_results = cross_validate(\n",
    "    estimator, X, y,\n",
    "    cv=cv, scoring=scoring, n_jobs=-1, return_train_score=True\n",
    ")\n",
    "\n",
    "# Output cross-validation metrics\n",
    "print(\"\\nCross-validation metrics for Logistic Regression on all features:\")\n",
    "for scorer in scoring.keys():\n",
    "    mean_train_score = np.mean(cv_results['train_' + scorer])\n",
    "    std_train_score = np.std(cv_results['train_' + scorer])\n",
    "    mean_test_score = np.mean(cv_results['test_' + scorer])\n",
    "    std_test_score = np.std(cv_results['test_' + scorer])\n",
    "    print(f\"  {scorer}:\")\n",
    "    print(f\"    Training: {mean_train_score:.4f} (+/- {std_train_score:.4f})\")\n",
    "    print(f\"    Testing: {mean_test_score:.4f} (+/- {std_test_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e47c06db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation metrics for XGBoost on all features:\n",
      "  accuracy:\n",
      "    Training: 0.8933 (+/- 0.0151)\n",
      "    Testing: 0.7839 (+/- 0.0277)\n",
      "  roc_auc:\n",
      "    Training: 0.9685 (+/- 0.0012)\n",
      "    Testing: 0.8153 (+/- 0.0381)\n",
      "  sensitivity:\n",
      "    Training: 0.8966 (+/- 0.0385)\n",
      "    Testing: 0.7562 (+/- 0.0974)\n",
      "  specificity:\n",
      "    Training: 0.8899 (+/- 0.0239)\n",
      "    Testing: 0.8096 (+/- 0.1198)\n",
      "  precision:\n",
      "    Training: 0.8947 (+/- 0.0193)\n",
      "    Testing: 0.8209 (+/- 0.0717)\n",
      "  npv:\n",
      "    Training: 0.8944 (+/- 0.0335)\n",
      "    Testing: 0.7730 (+/- 0.0464)\n",
      "  mcc:\n",
      "    Training: 0.7878 (+/- 0.0295)\n",
      "    Testing: 0.5795 (+/- 0.0509)\n",
      "  f1:\n",
      "    Training: 0.8949 (+/- 0.0169)\n",
      "    Testing: 0.7787 (+/- 0.0333)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, matthews_corrcoef,\n",
    "    f1_score, make_scorer, confusion_matrix, roc_auc_score, classification_report\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define custom scorers\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "def npv_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fn = cm[1, 0]\n",
    "    return tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "# Create scorers dictionary\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'sensitivity': make_scorer(recall_score, zero_division=0),\n",
    "    'specificity': make_scorer(specificity_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'npv': make_scorer(npv_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'f1': make_scorer(f1_score, zero_division=0)\n",
    "}\n",
    "\n",
    "# Initialize the estimator\n",
    "estimator = XGBClassifier(use_label_encoder=False, eval_metric='logloss', max_depth=2, n_estimators=50, random_state=0)\n",
    "\n",
    "# Set up the stratified k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform cross-validation on the entire dataset\n",
    "cv_results = cross_validate(\n",
    "    estimator, X, y,\n",
    "    cv=cv, scoring=scoring, n_jobs=-1, return_train_score=True\n",
    ")\n",
    "\n",
    "# Output cross-validation metrics\n",
    "print(\"\\nCross-validation metrics for XGBoost on all features:\")\n",
    "for scorer in scoring.keys():\n",
    "    mean_train_score = np.mean(cv_results['train_' + scorer])\n",
    "    std_train_score = np.std(cv_results['train_' + scorer])\n",
    "    mean_test_score = np.mean(cv_results['test_' + scorer])\n",
    "    std_test_score = np.std(cv_results['test_' + scorer])\n",
    "    print(f\"  {scorer}:\")\n",
    "    print(f\"    Training: {mean_train_score:.4f} (+/- {std_train_score:.4f})\")\n",
    "    print(f\"    Testing: {mean_test_score:.4f} (+/- {std_test_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45bc728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation metrics for Linear SVM on all features:\n",
      "  accuracy:\n",
      "    Training: 0.9299 (+/- 0.0169)\n",
      "    Testing: 0.7313 (+/- 0.0366)\n",
      "  roc_auc:\n",
      "    Training: 0.9809 (+/- 0.0051)\n",
      "    Testing: 0.7795 (+/- 0.0439)\n",
      "  sensitivity:\n",
      "    Training: 0.9255 (+/- 0.0342)\n",
      "    Testing: 0.6987 (+/- 0.1666)\n",
      "  specificity:\n",
      "    Training: 0.9345 (+/- 0.0225)\n",
      "    Testing: 0.7625 (+/- 0.1738)\n",
      "  precision:\n",
      "    Training: 0.9367 (+/- 0.0192)\n",
      "    Testing: 0.7893 (+/- 0.1036)\n",
      "  npv:\n",
      "    Training: 0.9249 (+/- 0.0331)\n",
      "    Testing: 0.7309 (+/- 0.0698)\n",
      "  mcc:\n",
      "    Training: 0.8608 (+/- 0.0340)\n",
      "    Testing: 0.4893 (+/- 0.0675)\n",
      "  f1:\n",
      "    Training: 0.9305 (+/- 0.0170)\n",
      "    Testing: 0.7166 (+/- 0.0674)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, matthews_corrcoef,\n",
    "    f1_score, make_scorer, confusion_matrix, roc_auc_score, classification_report\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define custom scorers\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "def npv_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fn = cm[1, 0]\n",
    "    return tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "# Create scorers dictionary\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'sensitivity': make_scorer(recall_score, zero_division=0),\n",
    "    'specificity': make_scorer(specificity_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'npv': make_scorer(npv_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'f1': make_scorer(f1_score, zero_division=0)\n",
    "}\n",
    "\n",
    "# Initialize the estimator with regularization parameter C\n",
    "estimator = LinearSVC(penalty='l1', loss='squared_hinge', C=0.5, max_iter=5000, random_state=0)\n",
    "\n",
    "# Set up the stratified k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform cross-validation on the entire dataset\n",
    "cv_results = cross_validate(\n",
    "    estimator, X, y,\n",
    "    cv=cv, scoring=scoring, n_jobs=-1, return_train_score=True\n",
    ")\n",
    "\n",
    "# Output cross-validation metrics\n",
    "print(\"\\nCross-validation metrics for Linear SVM on all features:\")\n",
    "for scorer in scoring.keys():\n",
    "    mean_train_score = np.mean(cv_results['train_' + scorer])\n",
    "    std_train_score = np.std(cv_results['train_' + scorer])\n",
    "    mean_test_score = np.mean(cv_results['test_' + scorer])\n",
    "    std_test_score = np.std(cv_results['test_' + scorer])\n",
    "    print(f\"  {scorer}:\")\n",
    "    print(f\"    Training: {mean_train_score:.4f} (+/- {std_train_score:.4f})\")\n",
    "    print(f\"    Testing: {mean_test_score:.4f} (+/- {std_test_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ab5f517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation metrics for Random Forest on all features:\n",
      "  accuracy:\n",
      "    Training: 0.8875 (+/- 0.0148)\n",
      "    Testing: 0.7776 (+/- 0.0580)\n",
      "  roc_auc:\n",
      "    Training: 0.9715 (+/- 0.0042)\n",
      "    Testing: 0.8356 (+/- 0.0502)\n",
      "  sensitivity:\n",
      "    Training: 0.8679 (+/- 0.0429)\n",
      "    Testing: 0.7092 (+/- 0.1271)\n",
      "  specificity:\n",
      "    Training: 0.9077 (+/- 0.0176)\n",
      "    Testing: 0.8456 (+/- 0.1021)\n",
      "  precision:\n",
      "    Training: 0.9075 (+/- 0.0123)\n",
      "    Testing: 0.8409 (+/- 0.0993)\n",
      "  npv:\n",
      "    Training: 0.8711 (+/- 0.0367)\n",
      "    Testing: 0.7507 (+/- 0.0773)\n",
      "  mcc:\n",
      "    Training: 0.7771 (+/- 0.0287)\n",
      "    Testing: 0.5725 (+/- 0.1193)\n",
      "  f1:\n",
      "    Training: 0.8865 (+/- 0.0178)\n",
      "    Testing: 0.7594 (+/- 0.0740)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, matthews_corrcoef,\n",
    "    f1_score, make_scorer, confusion_matrix, roc_auc_score, classification_report\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define custom scorers\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "def npv_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fn = cm[1, 0]\n",
    "    return tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "# Create scorers dictionary\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'sensitivity': make_scorer(recall_score, zero_division=0),\n",
    "    'specificity': make_scorer(specificity_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'npv': make_scorer(npv_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'f1': make_scorer(f1_score, zero_division=0)\n",
    "}\n",
    "\n",
    "# Initialize the estimator with regularization parameters suitable for small datasets\n",
    "estimator = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=6,\n",
    "    #min_samples_split=4,\n",
    "    #min_samples_leaf=2,\n",
    "    #max_features='log2',\n",
    "    #bootstrap=True,\n",
    "    #oob_score=True,\n",
    "    #n_jobs=-1,\n",
    "    #verbose=0,\n",
    "    #warm_start=False,\n",
    "    #class_weight=None,\n",
    "    #ccp_alpha=0.0,\n",
    "    #max_samples=None,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Set up the stratified k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform cross-validation on the entire dataset\n",
    "cv_results = cross_validate(\n",
    "    estimator, X, y,\n",
    "    cv=cv, scoring=scoring, n_jobs=-1, return_train_score=True\n",
    ")\n",
    "\n",
    "# Output cross-validation metrics\n",
    "print(\"\\nCross-validation metrics for Random Forest on all features:\")\n",
    "for scorer in scoring.keys():\n",
    "    mean_train_score = np.mean(cv_results['train_' + scorer])\n",
    "    std_train_score = np.std(cv_results['train_' + scorer])\n",
    "    mean_test_score = np.mean(cv_results['test_' + scorer])\n",
    "    std_test_score = np.std(cv_results['test_' + scorer])\n",
    "    print(f\"  {scorer}:\")\n",
    "    print(f\"    Training: {mean_train_score:.4f} (+/- {std_train_score:.4f})\")\n",
    "    print(f\"    Testing: {mean_test_score:.4f} (+/- {std_test_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7462d5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ece3596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87dfa9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3770c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228ba9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
